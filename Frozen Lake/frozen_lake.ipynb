{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THctwaD5E33L",
        "outputId": "2d38c5ae-244f-46bf-a4e8-9fbea8c4d4cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (2.5.2)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.11.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install gymnasium pyvirtualdisplay > /dev/null 2>&1\n",
        "%pip install pygame\n",
        "%pip install -Uqq ipdb\n",
        "%pip install gymnasium\n",
        "%pip install opencv-python\n",
        "import ipdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jn89fseE33M",
        "outputId": "d271cdd8-3595-4033-c607-99618cdba890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /Users/shalu/miniforge3/lib/python3.10/site-packages (4.9.0.80)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /Users/shalu/miniforge3/lib/python3.10/site-packages (from opencv-python-headless) (1.26.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hq0RmlV0E33N",
        "outputId": "f0f64e90-77bf-4c6c-9de7-2beb9b61f957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatic pdb calling has been turned ON\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "import pygame\n",
        "%pdb on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bxEy4WOCE33N"
      },
      "outputs": [],
      "source": [
        "class FrozenLake(gym.Env):\n",
        "  def __init__(self, grid_width, grid_height, grid_description):\n",
        "      self.width = grid_width\n",
        "      self.height = grid_height\n",
        "      self.description = grid_description\n",
        "      self.observation_space = spaces.Discrete(self.width * self.height)\n",
        "      self.action_space = spaces.Discrete(4)  # up, down, right, left\n",
        "      self.actions = {0:(0,-1), 1:(0,1), 2:(1,0), 3:(-1,0)} # up, down, right, left\n",
        "      self.agent_location = [0, 0]  # agent starts at top-left corner\n",
        "      self.rewards = {} # position, corresponding reward\n",
        "\n",
        "      # creates the grid using the description\n",
        "      self.grid = np.array(list(grid_description)).reshape(grid_width, grid_height)\n",
        "      self.rewards = np.zeros_like(self.grid, dtype=np.int32)\n",
        "      self.rewards[self.grid == 'I'] = 0 # ice - award of 0\n",
        "      self.rewards[self.grid == 'H'] = -100 # hole - reward of -100\n",
        "      self.rewards[self.grid == 'G'] = 100 # goal - reward of 100\n",
        "\n",
        "  def _get_obs(self):\n",
        "    return self.agent_location\n",
        "\n",
        "  def reset(self, seed=None, options=None):\n",
        "    super().reset(seed=seed)\n",
        "    self.agent_location = (0, 0)\n",
        "    row, col = self._get_obs()\n",
        "    return (row, col)\n",
        "\n",
        "  def compute_reward(self, observation):\n",
        "      return self.rewards[(observation[0], observation[1])]\n",
        "\n",
        "  def step(self, action):\n",
        "      observation = self._get_obs()\n",
        "\n",
        "      def take_action(action):\n",
        "        new_observation = tuple(x + y for x, y in zip(observation, self.actions[action]))\n",
        "        # updates the agent's location if it's within the grid and the new location isn't a hole\n",
        "        if 0 <= new_observation[0] < self.width and 0 <= new_observation[1] < self.height:\n",
        "            self.agent_location = new_observation\n",
        "\n",
        "      def is_episode_over():\n",
        "        row, col = self.agent_location\n",
        "        cell = self.grid[row][col]\n",
        "        if cell == 'H' or cell == 'G': # episode ends if agent reaches the goal or falls into a hole\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "      take_action(action) # processes the action parameter on the board\n",
        "      observation = self._get_obs() # observation after taking action\n",
        "      reward = self.compute_reward(observation)\n",
        "      terminated = is_episode_over() # true if episode completed and false otherwise\n",
        "\n",
        "      return observation, reward, terminated, False, None\n",
        "\n",
        "  def _render_frame(self, screen, window_width, window_height):\n",
        "    pass\n",
        "\n",
        "  def render(self, screen, window_width, window_height):\n",
        "    pygame.init()\n",
        "\n",
        "    # window dimensions\n",
        "    window_width = self.width * 50\n",
        "    window_height = self.height * 50\n",
        "\n",
        "    # colors\n",
        "    white = (255, 255, 255)\n",
        "    black = (0, 0, 0)\n",
        "    blue = (0, 0, 255)\n",
        "    red = (255, 0, 0)\n",
        "\n",
        "    # creates the window\n",
        "    screen = pygame.display.set_mode((window_width, window_height))\n",
        "    pygame.display.set_caption('Grid World Environment')\n",
        "\n",
        "    # default screen\n",
        "    screen.fill(white)\n",
        "\n",
        "    # draws the grid based on the description\n",
        "    for i, block_type in enumerate(self.description):\n",
        "        row = i // self.width\n",
        "        col = i % self.width\n",
        "        x = col * 50\n",
        "        y = row * 50\n",
        "\n",
        "        if block_type == 'I': # Ice block\n",
        "            pygame.draw.rect(screen, blue, (x, y, 50, 50))\n",
        "        elif block_type == 'H': # Hole\n",
        "            pygame.draw.rect(screen, black, (x, y, 50, 50))\n",
        "        elif block_type == 'G': # Goal\n",
        "            pygame.draw.circle(screen, red, (x + 25, y + 25), 20)\n",
        "\n",
        "    # draws the agent\n",
        "    agent_row, agent_col = self.agent_location\n",
        "    agent_x = agent_col * 50 + 25\n",
        "    agent_y = agent_row * 50 + 25\n",
        "    pygame.draw.circle(screen, black, (agent_x, agent_y), 10)\n",
        "\n",
        "    # updates the display\n",
        "    pygame.display.update()\n",
        "\n",
        "    # event loop\n",
        "    for event in pygame.event.get():\n",
        "        if event.type == pygame.QUIT:\n",
        "            pygame.quit()\n",
        "\n",
        "    return self._render_frame(screen, window_width, window_height)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Your code to read and process the image\n",
        "\n",
        "# Display the image\n",
        "cv2_imshow(img_bgr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "gRjZXtHhFYlC",
        "outputId": "49f2d005-37e4-4e53-c34f-814cb5ab7203"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=150x150>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJYAAACWCAIAAACzY+a1AAACgUlEQVR4nO3dwW6DMBQFUVP1/385XUTqhpAY/EyYy8yySm3UIyMaB7K09mjW2/LtA3jRz7cPwEaTEJ+E+CTEJyE+CfFJiE9CfBLikxCfhPgkxCchPgnx/X77AOa13hjK3FaLJNza1Xv+PA0y70T6cVf2itu2I4URdvJEKSYR7oLJUYwhPEASohhDeN8yCA+vp4SFmEF46yTEJyE+CfFJiC+D8PDbngnvl2YQ3roYwgPrKWEJtiDCtpMkxK9lEbZumBy/FkfYOnii/Frorv0TyQ9e4MsEW5d3Ir1dEuKTEJ+E+CTEJyE+CfFJiE9CfBLikxCfhPgkxCchvsveVHCXraLxXIX4JMQnIT4J8UmIT0J8EuKTEJ+E+CTEJyE+CfFJiE9CfBLikxCfhPgkxCchPgnxSYhPQnwS4pMQn4T4JMQnIT4J8UmIT0J8EuKTEJ+E+CTEJyE+CfFJiE9CfBLikxCfhPgkxCchPgnxSYhPQnwS4pMQn4T4Fp+/29/jkn8qVyE+CfFJiE9CfMHfqH29lo2vlBi7TJJwflty6xccspRwZh/xXr5+J6SEc9qLt/7dbkgvZyY04rd/EAmrK/HbM5SEpRX6dQ8oYV3lfn3DSljUJL+OwSWsaKrfpykkxCfhcCcswbcTSYhPwrFOW4Lb00mIT0J8Eg508ll0Y1IJ8UmIT0J8EuKTEJ+E+CTEJ+FAX7lNZjWphPgkxCfhWCefS19NJyE+CYc7bSFuTCQhPgkrOmEhbk8hYVFTFd8OLmFdkxQ/DSthaeWKHQNKWF2hYt9QEk6oRLF7EO/yndMT4Njno7xR+0LthfRxCRftH8aHluCb81+HlzP4JMQnIT4J8f0BcTtPO6OOqTsAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import pygame\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Assuming FrozenLake, pygame, and lake objects are defined earlier in your code\n",
        "\n",
        "# Initialize Pygame display\n",
        "window_width = 400\n",
        "window_height = 400\n",
        "pygame.init()\n",
        "screen = pygame.display.set_mode((window_width, window_height))\n",
        "\n",
        "for i in range(1):\n",
        "    lake.reset()\n",
        "    terminated = False\n",
        "    while not terminated:\n",
        "        action = lake.action_space.sample()\n",
        "        observation, reward, terminated, truncated, info = lake.step(action)\n",
        "        lake.render(screen, window_width, window_height)\n",
        "\n",
        "        # Convert Pygame surface to numpy array and then to BGR format\n",
        "        view = pygame.surfarray.array3d(screen)\n",
        "        view = np.transpose(view, (1, 0, 2))\n",
        "        img_bgr = cv2.cvtColor(view, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # Display the image\n",
        "        cv2_imshow(img_bgr)\n",
        "        time.sleep(0.5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "-MBy2nZdFyif",
        "outputId": "29f72d9c-c333-4aab-abdb-7a15aae2aa3a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=150x150>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJYAAACWCAIAAACzY+a1AAACfElEQVR4nO3dQW7iMABAURjN/a/cWVTqBlKS2A780fvLitqoT04TTOB+u33dtLf7u5/Ak/68+wloNIT5EOZDmA9hPoT5EOZDmA9hPoT5EOZDmA9hPoT5/s4Y5HELxgbWdQ0Sbu2fff8c5BWNHEhf7n9+4gbp/9dpwp08FJd3jvAQDMW1nSA8QUJxYS4q8h0lPL2eLMRVWYX5EOZDmA9hPoT5jhKeftnT66WrsgrznSA8sZ4swYWdW4WHSPit7fSBdCcMv+WN/C98ycPvigZ37b+RvPHinU157wywd+aiIh/CfAjzIcyHMB/CfAjzIcyHMB/CfAjzIcyHMB/CfB97q4MNrL1ZhfkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPnuPn93f18f+aeyCvMhzIcwH8J8U75RW/u6b3ylxNhpEsL1bck9PuCUJcKVvcR7+viDkAjXdBTv8Xd3QzqdWdCI3/FBEM5uit+RoRBObaLf7gERzmu6375hEU5qkd+OwRHOaKnfqykQ5kM43AVL8NeJEOZDONZlS3B7OoT5EOZDONDFR9GNSRHmQ5gPYT6E+RDmQ5gPYT6EA73lNpmHSRHmQ5gP4VgXH0ufTYcwH8LhLluIGxMhzIdwRhcsxO0pEE5qqeKvgyOc1yLFV8MinNp0xR0DIpzdRMV9QyFc0BTF3YO4y3dN3wDn3h/lRu0P6iikj0v40H5gfGhJvjVXHU5n8iHMhzAfwnz/ADssTzvj8kThAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=150x150>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJYAAACWCAIAAACzY+a1AAACfElEQVR4nO3dQW7iMABAURjN/a/cWVTqBlKS2A780fvLitqoT04TTOB+u33dtLf7u5/Ak/68+wloNIT5EOZDmA9hPoT5EOZDmA9hPoT5EOZDmA9hPoT5/s4Y5HELxgbWdQ0Sbu2fff8c5BWNHEhf7n9+4gbp/9dpwp08FJd3jvAQDMW1nSA8QUJxYS4q8h0lPL2eLMRVWYX5EOZDmA9hPoT5jhKeftnT66WrsgrznSA8sZ4swYWdW4WHSPit7fSBdCcMv+WN/C98ycPvigZ37b+RvPHinU157wywd+aiIh/CfAjzIcyHMB/CfAjzIcyHMB/CfAjzIcyHMB/CfB97q4MNrL1ZhfkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPnuPn93f18f+aeyCvMhzIcwH8J8U75RW/u6b3ylxNhpEsL1bck9PuCUJcKVvcR7+viDkAjXdBTv8Xd3QzqdWdCI3/FBEM5uit+RoRBObaLf7gERzmu6375hEU5qkd+OwRHOaKnfqykQ5kM43AVL8NeJEOZDONZlS3B7OoT5EOZDONDFR9GNSRHmQ5gPYT6E+RDmQ5gPYT6EA73lNpmHSRHmQ5gP4VgXH0ufTYcwH8LhLluIGxMhzIdwRhcsxO0pEE5qqeKvgyOc1yLFV8MinNp0xR0DIpzdRMV9QyFc0BTF3YO4y3dN3wDn3h/lRu0P6iikj0v40H5gfGhJvjVXHU5n8iHMhzAfwnz/ADssTzvj8kThAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=150x150>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJYAAACWCAIAAACzY+a1AAACgUlEQVR4nO3dwW6DMBQFUVP1/385XUTqhpAY/EyYy8yySm3UIyMaB7K09mjW2/LtA3jRz7cPwEaTEJ+E+CTEJyE+CfFJiE9CfBLikxCfhPgkxCchPgnx/X77AOa13hjK3FaLJNza1Xv+PA0y70T6cVf2itu2I4URdvJEKSYR7oLJUYwhPEASohhDeN8yCA+vp4SFmEF46yTEJyE+CfFJiC+D8PDbngnvl2YQ3roYwgPrKWEJtiDCtpMkxK9lEbZumBy/FkfYOnii/Frorv0TyQ9e4MsEW5d3Ir1dEuKTEJ+E+CTEJyE+CfFJiE9CfBLikxCfhPgkxCchvsveVHCXraLxXIX4JMQnIT4J8UmIT0J8EuKTEJ+E+CTEJyE+CfFJiE9CfBLikxCfhPgkxCchPgnxSYhPQnwS4pMQn4T4JMQnIT4J8UmIT0J8EuKTEJ+E+CTEJyE+CfFJiE9CfBLikxCfhPgkxCchPgnxSYhPQnwS4pMQn4T4Fp+/29/jkn8qVyE+CfFJiE9CfMHfqH29lo2vlBi7TJJwflty6xccspRwZh/xXr5+J6SEc9qLt/7dbkgvZyY04rd/EAmrK/HbM5SEpRX6dQ8oYV3lfn3DSljUJL+OwSWsaKrfpykkxCfhcCcswbcTSYhPwrFOW4Lb00mIT0J8Eg508ll0Y1IJ8UmIT0J8EuKTEJ+E+CTEJ+FAX7lNZjWphPgkxCfhWCefS19NJyE+CYc7bSFuTCQhPgkrOmEhbk8hYVFTFd8OLmFdkxQ/DSthaeWKHQNKWF2hYt9QEk6oRLF7EO/yndMT4Njno7xR+0LthfRxCRftH8aHluCb81+HlzP4JMQnIT4J8f0BcTtPO6OOqTsAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=150x150>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJYAAACWCAIAAACzY+a1AAACJUlEQVR4nO3dwW7iMBRA0TDq//9yZzFSN5DiEDtwNeeu6XPUI6MgEXPbtu9No93efQEP+vPuC9DZEOZDmA9hPoT5EOZDmA9hPoT5EOZDmA9hPoT5EOZDmA9hPoT5EOZDmA9hPoT5EOZDmA9hPoT5EOZDmA9hPoT5EOZDmA9hPoT5EOZDmA9hPoT5EOZDmA9hPoT5EOZDmA9hPoT5EOZDmA9hPoT5PvGY223bnFU8nl2YD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOYD2E+hPkQ5kOY7+b83fG+P/JfZRfmQ5gPYT6E+b7efQH/U7edn5Q4d5uEcH17cvcveMkS4cqe4j18/UFIhGs6inf/t8OQbmcWdMbv+BCEs5vid2QUwqlN9BseiHBe0/3GxiKc1CK/geEIZ7TU79kSCPMhPN0FW/DXhRDmQ3iuy7bg/nII8yHMh/BEF7+L7iyKMB/CfAjzIcyHMB/CfAjzITzRWx6TuVsUYT6E+RCe6+L30kfLIcyH8HSXbcSdhRDmQzijCzbi/hIIJ7VU8dfhCOe1SPHZWIRTm644MBDh7CYqjo1CuKApisNDPOW7pn8Ar30/yoPaH9RRSMclfGg/MA4tybfmU4fbmXwI8yHMhzDfX9ixQDTwEwXCAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "S77N06_6E33O"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "class QLearning():\n",
        "    def __init__(self, env, exploration, gamma, alpha, obs_space_n, action_space_n):\n",
        "        self.env = env\n",
        "        self.exploration = exploration\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        self.obs_space_n = obs_space_n\n",
        "        self.action_space_n = action_space_n\n",
        "\n",
        "        # initializes q-table with rewards from FrozenLake class\n",
        "        self.q_table = np.zeros((env.width, env.height, action_space_n))\n",
        "        self.q_table[:, :, :] = env.rewards[:, :, np.newaxis]\n",
        "\n",
        "    def sample_action(self, observation):\n",
        "        if random.uniform(0, 1) < self.exploration:\n",
        "            return random.randint(0, self.action_space_n - 1) # random action\n",
        "        else:\n",
        "            return np.argmax(self.q_table[observation[0], observation[1]])\n",
        "\n",
        "    def update_table(self, observation, action, reward, new_observation, terminated):\n",
        "        current_q_value = self.q_table[observation[0], observation[1], action]\n",
        "        if terminated:\n",
        "            target_q_value = reward\n",
        "        else:\n",
        "            max_future_q_value = np.max(self.q_table[new_observation[0], new_observation[1]])\n",
        "            target_q_value = reward + self.gamma * max_future_q_value\n",
        "        new_q_value = ((1 - self.alpha) * current_q_value) + (self.alpha * target_q_value)\n",
        "        self.q_table[observation[0], observation[1], action] = new_q_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "itOqoOJwE33O"
      },
      "outputs": [],
      "source": [
        "lake = FrozenLake(5, 5, \"IIIHIHIHHHIIIIGIIIIHIIIIH\")\n",
        "q_learning = QLearning(lake, .3, .99, .9, lake.width * lake.height, lake.action_space.n)\n",
        "\n",
        "# trains the policy using QLearning\n",
        "num_episodes = 100000\n",
        "for episode in range(num_episodes):\n",
        "    for row in range(lake.width):\n",
        "        for col in range(lake.height):\n",
        "            observation = (row, col)\n",
        "            if lake.grid[row][col] == 'I':\n",
        "                action = q_learning.sample_action(observation)\n",
        "                new_observation = tuple(x + y for x, y in zip(observation, lake.actions[action]))\n",
        "                if not (0 <= new_observation[0] < lake.width and 0 <= new_observation[1] < lake.height): # if out of bounds, no change\n",
        "                    new_observation = observation\n",
        "                q_learning.update_table(observation, action, 0, new_observation, False) # updates the Q-table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "yvHbWu1yE33O",
        "outputId": "7d93313a-04cd-49e7-f172-bb6c47ac1ac7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=250x250>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD6CAIAAAAHjs1qAAADy0lEQVR4nO3dwa6aQABAUWn6/79sF026EZ8DCoO95ywNzBBzHYWgLrfb/cZ3W2YfwKordvVr9gHAeeROiNwJkTshcidE7oTInRC5EyJ3QuROiNwJkTshcidE7oTInRC5EyJ3QuROiNwJkTshcidE7oTInRC5EyJ3QuROiNwJkTshcidE7oTInRC5EyJ3QuROiNwJkTshcidE7oTInRC5EyJ3QuROiNwJkTshcidE7oTInRC5EyJ3QpbZB/DMffYBrLrs08UQqzshcidE7oTInRC5EyJ3QuROiNwJkTshcidE7oTInRC5EyJ3QuROiNwJkTshcidE7oTInRC5EyJ3QuROiNwJkTshcidE7oTInRC5EyJ3QuROiNwJkTshcidE7oTInRC5EyJ3QuROiNwJkTshcidE7oTInRC5EyJ3QuROiNwJkTshy+12n30M/Iful8zK6k6I3AmROyFyJ+T37AOANcuy/vh7p8By50qeVf64wa7u5c41vAx9dfuN0cud2baG/rjvcPROVZnqnda3DyJ35vlI61uGkjuTfLD14QHlzgwfb31sWLlzuoNaHxhc7pzr0NZfTeFCJBf12Oz79xRb3TnR2NK+rLX+w+PjE8mda3kZ9DsfhuTOWQaW9sGUx94jVraSO1exadnet8bLnUvYke+OXeTOKU64/jgwqdyZb/dLYeuOcidE7oTInRC5EyJ3QuTOfLvv/dq6o9w5xZSfSH2YVO5cwo5Xw45d5M5VbMp335uF3DnLwOeZwYiHNlubTu5cy8uU3zkJkDsnGjthvT9p+tnj4xP5rioXdcSlHKs75zrhiuTzKeTO6Q4t/sfB5c4MBxX/ali5M8nHix8YUO7M88Hix4aSO1N9pPjhQVyIZLa/se777rY/q+ErbY3eX5Hx9f5F7I8mCTnmSqVTVULkTojcCZE7IcsxN1rCjN9AfcXqTojcCZE7IXInRO6EyJ0QuRMid0LkTojcCZE7IXInRO6EyJ0QuRMid0LkTojcCZE7IXInRO6EyJ0QuRMid0LkTojcCZE7IXInRO6EyJ0QuRMid0LkTojcCZE7IXInRO6EyJ0QuRMid0LkTojcCZE7IXInRO6EyJ0QuRMid0LkTojcCZE7IXInRO6EyJ0QuRMid0LkTojcCZE7IXInRO6EyJ0QuRMid0LkTojcCZE7IXInRO6EyJ0QuRMid0LkTojcCZE7IXInRO6EyJ0QuRMid0LkTojcCZE7IXInRO6EyJ0QuRMid0LkTojcCZE7IXInRO6EyJ0QuRMid0LkTojcCZE7IX8A47xS/hmT+PIAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import pygame\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "q_learning.exploration = 0.0\n",
        "\n",
        "# Assuming lake object is defined earlier in your code\n",
        "\n",
        "# Initialize Pygame display\n",
        "window_width = 400\n",
        "window_height = 400\n",
        "pygame.init()\n",
        "screen = pygame.display.set_mode((window_width, window_height))\n",
        "\n",
        "for i in range(1):\n",
        "    observation = lake.reset()\n",
        "    terminated = False\n",
        "    lake.render(screen, window_width, window_height)\n",
        "\n",
        "    while not terminated:\n",
        "        action = q_learning.sample_action(observation)\n",
        "        observation, reward, terminated, truncated, info = lake.step(action)\n",
        "        lake.render(screen, window_width, window_height)\n",
        "\n",
        "        # Convert Pygame surface to numpy array and then to BGR format\n",
        "        view = pygame.surfarray.array3d(screen)\n",
        "        view = np.transpose(view, (1, 0, 2))\n",
        "        img_bgr = cv2.cvtColor(view, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # Display the image\n",
        "        cv2_imshow(img_bgr)\n",
        "        time.sleep(0.5)\n",
        "        clear_output(wait=True)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}